-----------------
João Brito, m9984
-----------------

1. O decaimento de pesos é uma técnica cujo objetivo consiste em impedir que os pesos fiquem demasiado grandes, em valor absoluto. Tal situação poderia levar a 
que o modelo entrasse em overfit, já os neurónios iriam receber entradas altamente pesadas e influentes, potencialmente capturando features apenas presentes no
conjunto de treino e não no de teste (má generalização).
De forma prática, manifesta-se com a adição de um termo à função de custo (nas suas variantes L1 e L2), que penaliza pesos demasiado grandes/influentes.


2. 
    Considerando: 1  1  0  1
                  b1 b2 b3 b4

    Temos:
        g_i = 1 (b_1 ^ ~b_2 v ~b_1 ^ b2) (b_2 ^ ~b_3 v ~b_2 ^ b3) (b_3 ^ ~b_4 v ~b_3 ^ b4)
        g_i = 1 (1 ^ 0 v 0 ^ 1) (1 ^ 1 v 0 ^ 0) (0 ^ 0 v 1 ^ 1)
        g_i = 1 (0 v 0) (1 v 0) (0 v 1)
        g_i = 1 0 1 1


3. A definição de velocidade está intimamente ligada com a noção de deslocamento. Mais concretamente, deslocamento em função de um intervalo de tempo. Ora, um 
deslocamento é medido com base na variação de posição (variação de "x" e "y", por exemplo). Assim, se a velocidade se referir à variação/deslocamento em cada coordenada,
então esta pode ser adicionada a coordenadas tradicionais. A título de exemplo:

x(t-1) = (0,0)
v(t) = (1,2)

x(t) = (0+1,0+2) = (1,2), que é a nova posição da partícula dada a velocidade que apresenta no instante "t".


4. Um sistema difuso é adequado em situações nas quais os espaço de entrada e saída são difusos e é necessária a noção de pertença a um conjunto. Mesmo que os dados
não estejam no formato difuso, a sua representação/processamento e respetivo output podem ser. A noção de temperatura, pode ser medida em Celsius (ou seja quatificada)
mas o sistema pode querer representar essa informação em "quente" ou "frio". Tais representações são difusas e a saída do sistema será um grau de pertença a cada um desses conjuntos.


5. O artigo que li abordou uma nova função de ativação chamada Mish. Esta função é definida com base na tanh e softplus do seguinte modo: 
mish(x) = x * tanh( softplus(x) ).

De entre as propriedades que apresenta, ressalto:

    - Não saturação, importante para impedir que os pesos deixem de ser atualizados por causa de derivadas nulas ou quase nulas;
    - Suave e contínua, o que garante uma transição suave entre ativações e garante derivadas ao longo de todo o domínio;
    - Regularização intrínseca para inputs negativos, importante para que valores demasiado negativos não sejam mantidos (são esquecidos);
    - Pequenas ativações para inputs negativos pequenos, que permite o modelo manter a sua expressividade.

No artigo é constantemente comparada com a Swish e a ReLU, demonstrando nos testes apresentados ter ganhos de décimas (ou por margens semelhantes) na métrica de accuracy.
Como caraterística menos positva e devido à sua fórmula, a Mish é mais custosa, computacionalmente, quando comparada com a Swish e, especialmente, a ReLU.

Resumindo, o propósito da função é manter as qualidades e comportamento geral da função ReLU (função por defeito em muitas aplicações) e resolver alguns problemas desta 
(problema do neurónio morto, devido aos gradientes quase nulos, e falta de suavidade).


6. Foram utilizados cromossomas com 2 genes cada. Tal decisão baseou-se no facto de cada cromossoma ser uma representação de uma potencial solução para o problema,
e os genes serem as caraterísticas dessas soluções/cromossomas. Ora, como no sistema apresentado existiam 2 variáveis ("x" e "y"), podemos considerar essas variáveis como as
caraterísticas do nosso problema. A derivação natural deste enquadramento é que cromossomas com 2 genes seriam adequados para resolver o exercício referido.